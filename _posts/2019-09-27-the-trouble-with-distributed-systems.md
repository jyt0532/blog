---
layout: post
title: Designing Data-Intensive Application - The Trouble with Distributed Systems
comments: True 
subtitle: 分佈式系統的麻煩
tags: systemDesign 
author: jyt0532
excerpt: 
---

這是Designing Data-Intensive Application的第二部分第四章節: 分佈式系統的麻煩

本文所有圖片或代碼來自於原書內容
{% include copyright.html %}

## 前言

在前幾章中反覆出現的問題是 系統該如何處理錯誤情況 比如[副本故障切換](/2019/02/12/replication/#section-4) [複製延遲](/2019/02/12/replication/#複製延遲問題) 或是[事務控制](/2019/04/29/weak-isolation-levels/)

即使我們在之前談了很多錯誤 但我們還不夠悲觀 這篇文章我們要把悲觀最大化 假設任何可能出錯的東西都出錯

![Alt text]({{ site.url }}/public/pessimistic.jpeg)

我們會討論所有分布式系統**實踐上**可能會遇到的問題 了解哪些東西是我們能依賴的 哪些東西是我們不能過分依賴的

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
本章對分佈式系統中可能出現的問題進行徹底的悲觀和沮喪的總結 我們會討論

1.網絡的問題（“無法訪問的網絡”

2.時鐘和時序問題（“不可靠時鐘”）

3.我們將討論他們可以避免的程度。 所有這些問題的後果都是困惑的，

所以我們將探索如何思考一個分佈式系統的狀態，

以及如何推理髮生的事情（“知識，真相和謊言”）
@@@@@@@@@@@@@@@@@

### 故障與部分失效

單個計算機上的軟體沒有根本性的不可靠原因 當硬體正常工作時 相同的操作總是產生相同的結果 我們稱為deterministic 如果你有硬體上的問題 那你通常會是整個系統故障 所以一個跑軟體的個人計算機 要馬功能完好 要馬整組壞掉 不會介於兩者之間

但如果你是運行在多台計算機上的軟體時 那情況就完全不同 分布式系統並不是理想的模型很有可能系統的**某部分**會以不可預知的方式被破壞 我們稱為**部分失效(partial failure)** 頭痛的地方在於部分失效是**不確定性的(nonderterministic)**

如果你試圖想做涉及多個節點和網路的事情 這有時會成功有時會失敗 更慘的是如果是網路壞掉 你甚至無法知道你想做的事是否成功了 因為消息通過網路傳播的時間也是不確定的

這種不確定性和部分失效的可能性 使得分佈式系統難以工作


#### 雲計算與超級計算機

關於如何建構一個大型計算機有一個光譜

1.光譜的一端 是使用HPC(High-performance computing) 就是一個擁有數千CPU的超級猛電腦 可以用來計算密集的計算機任務 比如說天氣預報或是分子動力學

2.光譜的另外一端 則是雲計算(cloud computing) 通常是多個數據中心以乙太網路連結 彈性的按照需求/流量計費

3.一般企業使用的數據中心模型就是介於兩者之間

在光譜的不同地方 會導致不同的故障處理方式 在超級計算機的那一端 作業通常會不時地會將計算的狀態存盤到持久存儲中 如果一個節點出現故障 通常的解決方案是簡單地停止整個集群的工作負載 故障節點修復後 計算從上一個檢查點重新開始

因此 超級計算機更像是一個單節點計算機而不是分佈式系統 它通過讓部分失敗升級為完全失敗來處理部分失敗

但在本書中 我們希望處理的是互聯網服務的系統 這些系統通常與超級計算機有很大不同

1.許多與互聯網有關的應用程序都是Online的 我們必須要一直available! 讓服務暫停是不可接受的 不像天氣預測的批處理計算 可以隨時停止之後重新啟動

2.超級計算機通常由專用硬件構建而成 每個節點相當可靠 雲服務的節點是由商品機器構建而成的 雖然因為規模經濟一次購買大量比較便宜 但具有較高的故障率

3.超級計算機通常使用專門的網絡拓撲結構 例如多維網格和環面 這些為HPC工作負載提供了更好的性能 大型數據中心網路則是基於IP和已太網 以閉合拓撲排列提供更高的二等分帶寬

4.系統越大 其組件之一就越有可能發生變化 當你修好一個壞掉的東西時 別的東西可能也壞了 在一個有成千上萬個節點的系統中 我們可以合理的認為總是有一些東西壞掉了 所以你必須一直分配部分的資源在修理節點上

5.如果系統可以容忍發生故障的節點 並繼續保持整體工作狀態 那麼這對於操作和維護非常有用 比如[滾動升級](/2019/01/24/encoding-and-evolution/)(一次重新啟動一個節點 系統繼續服務用戶不中斷)

6.在地理位置分布部署中(保持數據在地理位置上接近用戶以減少訪問延遲) 通信很可能通過互聯網進行 與本地網絡相比 通信速度緩慢且不可靠 超級計算機通常假設它們的所有節點都靠近在一起 


如果要使分佈式系統工作 就必須接受部分故障的可能性 並在軟件中建立容錯機制

換句話說 我們需要利用**不可靠的組件構建一個可靠的系統** 別忘了沒有完美的[可靠性](/2019/01/05/reliable-scalable-and-maintainable-application/) 我們需要理解我們可以實際承諾的限制

### 不可靠的網路

我們在本書中關注的都是[無共享的架構](/2019/09/27/distributed-data/#無共享架構) 網路就是機器跟機器間唯一的溝通途徑 意思就是說每台機器都不能訪問別台機器的硬碟跟內存

互聯網和數據中心中的大多數內部網路都是異步分組網路(asynchronous packet networks) 在這種網絡中 一個節點可以向另一個節點發送一個消息(一個數據包) 但是網路不能保證它什麼時候到達或者是否到達 可能出錯的地方如下

1.請求丟失(有人拔網路線)

2.請求正在queue裡排隊 等待晚點送達(網路超載或收件人超載)

3.遠程節點可能已經失效(崩潰或關機)
%%%%%%%%%%%%%%%%%%%%%%%%
4.遠程節點可能暫時停止了響應(垃圾回收暫停 參閱暫停進程)
%%%%%%%%%%%%%%%%%%%%%%%%%%
5.遠程節點可能已經處理了請求 但是網路上的響應已經丟失(網路交換機配置錯誤)

6.遠程節點可能已經處理了請求 響應已經被延遲 稍後才會送達(網路超載或寄件人超載)

當你發送一個封包且沒有得到回應 你並不知道是哪步出錯 可能(a)請求丟失 (b)遠端節點關閉 (c)響應丟失
 
![Alt text]({{ site.url }}/public/DDIA/DDIA-8-1.png)

處理這個問題的通常方法是**超時(Timeout)** 也就是過一段時間沒收到響應就放棄 但也不是放棄就沒事 你並不知道對方有沒有正確地收到這個消息並處理

#### 檢測故障

許多系統需要自動檢測故障節點 比如說

1.負載平衡器需要停止向已死亡的節點發送請求 並把他移出輪值表(out of rotation)

2.單主複製功能的分佈式數據庫中 如果主庫失效 則需要將從庫之一升級為新主庫

不幸的是 因為網路的不確定性 使得你很難判斷一個節點是否工作 但在某些特定的網路故障我們有些明確的feedback

1.如果你可以到達運行節點的機器 但沒有進程正在listen to the port 這我們就可以從HTTP Status Code明確的知道是遠端問題不是網路問題

2.有可能在router那端它就知道你想要連接的ip位置已經死了 那就會給你一個特別的response

總的來說 如果出了什麼問題 你可能會在某個level得到有關錯誤的回應(router level, tcp level, application level) 但一般來說最常見的狀況 就是你根本沒有得到任何回應 你唯一能做的就是重試幾次 每次都timeout的話就基本可以確定對面節點掛了 

#### 超時與無窮的延遲	

如果超時是檢測故障的唯一可靠方法 那麼超時應該等待多久? 不幸的是這題沒有簡單的答案

超時設定的太短 可能遠端節點只是處理得慢點你就說他掛了 把請求發給別人 到最後這個請求就會被做兩次

而且當你把請求轉移到其他節點時 會給其他節點和網路帶來額外的負擔 特別是那個你以為他死掉的節點 他會讓你覺得死掉很可能就是因為他現在手上的工作太多 你過早宣告他死亡只會讓事情更嚴重 因為他其實沒死掉 但你把他的工作交給別人 然後你就會以為別人死掉 然後就一連串的一個接一個真的死掉 我們稱為cascading failure

做個簡單的假設吧 

d: 網路可以保證一個數據被傳遞的最大延遲 每個數據包要碼在d內傳送 要麼丟失 但是傳遞永遠不會比d更長

r: 保證一個非故障節點總是在r時間內處理一個請求

在這種情況下 你就可以保證每個成功的請求在`2d + r`時間內都能收到響應 如果您在此時間內沒有收到響應 你就可以說網絡或遠程節點掛了

##### 網絡擁塞和排隊

計算機網路上數據包延遲的變數通常是由於排隊 而且有不少地方需要排隊

1.如果多個不同的節點同時嘗試將數據包發送到同一目的地 則網路交換機必須將它們排隊並將它們逐個送入目標

![Alt text]({{ site.url }}/public/DDIA/DDIA-8-2.png)

在請求很多的時候 數據包可能需要等待一段時間才能獲得一個插槽slot 如果傳入的數據太多 交換機隊列已經被填滿的話 數據包將被丟棄(需要重新發送數據包) 即使是在網路運作良好正常的情況下

2.而且當數據包到達目標機器時 如果所有CPU內核當前都處於繁忙狀態 則來自網路的傳入請求將被送到操作系統排隊 直到應用程序準備好處理它為止

3.在虛擬化環境中 正在運行的操作系統經常暫停幾十毫秒 由另一個虛擬機使用CPU內核 在這段時間內，虛擬機不能從網絡中消耗任何數據 所以傳入的數據也需要排隊

4.TCP執行流量控制(flow control) 也稱為擁塞避免(congestion avoidance)或背壓(backpressure) 其中發送節點限制自己的發送速率以避免網路或接收節點過載

> **TCP vs UDP**
>
> 一些對延遲敏感的應用程序(視訊 講電話等等) 使用UDP而不是TCP 這是在可靠性和和延遲可變性之間的折衷 由於UDP不執行流量控制並且不重傳丟失的分組 所以避免了可變網路延遲的一些原因

以上提的這些因素都會造成網路延遲的變化 通常你需要透過不斷的實驗 來測量延長的網路往返時間和多台機器的分佈 再考慮應用程序的特性 來決定**故障檢測延遲**與**過早超時風險**之間的適當折衷


#### 延遲和資源利用

你可以把**延遲變化**視為**動態資源分區**的結果

假設兩台電話交換機之間有一條線路 可以同時進行10000個呼叫 通過此線路切換的每個電路都佔用其中一個呼叫插槽 
因此 您可以將線路視為可由多達10000個並發用戶共享的資源 **資源以靜態方式分配**: 意思就是即使您現在是電話上唯一的電話 並且其他9999個插槽都未使用 您的電路仍將分配與所有插槽都被使用時相同的固定數量的帶寬

相比之下 互聯網動態分享網路帶寬 發送者互相推擠已儘可能快地通過網路傳送 這種方法最大的好處就是無時無刻都最大化了資源的使用

CPU也會出現類似的情況 如果您在多個線程間動態共享每個CPU內核 則有一個線程有時必須等待操作系統的運行隊列 而另一個線程正在運行 這樣線程可以暫停不同的時間長度 但跟每個線程分配靜態數量的CPU週期相比 這會更好地利用硬件 而更好的硬件利用率也是使用虛擬機的重要動機

如果資源是靜態分區的(專用帶寬分配) 則在某些環境中可以實現**延遲保證**(就是我保證多久可以送的到)  但是 這是以降低利用率為代價的 換句話說就是比較昂貴

另一方面 動態資源分配的多租戶提供了更好的利用率 所以它更便宜 但它具有可變延遲的缺點

網路中的可變延遲不是一種自然規律 而只是成本/收益權衡的選擇

